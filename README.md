# BlindVision

Blind individuals face challenges in navigating their surroundings without a mobility aid, including difficulty detecting obstacles, navigating unfamiliar environments, and increased risk of accidents. This can limit their independence and lead to social isolation. A smart walking stick can help address these challenges by providing enhanced obstacle detection, navigation assistance, and other features to improve safety, independence, and overall quality of life.

# Background and motivatoion
According to the World Health Organization (WHO), there are approximately 285 million visually impaired individuals in the world, with 39 million of them being blind.
Visually impaired individuals face numerous challenges in their daily lives, including mobility limitations, orientation difficulties, and safety concerns.
Traditional assistive technologies such as canes and guide dogs have limitations, and they cannot detect obstacles such as low hanging branches or potholes.

# Our solution
We aim to develop a technology that helps visually impaired individuals to navigate their surroundings with greater independence and confidence.
It uses a deep neural network called YOLO v8 to detect objects in real-time from images captured by a camera that would be mounted on the stick.
It provides audio feedback to the user about the distance, location, and size of the objects detected.

# Objectives
To provide real-time, accurate, and user-friendly assistance to visually impaired individuals in identifying objects in their environment.
To improve the safety and independence of visually impaired individuals by helping them navigate their surroundings more effectively.
To develop a deep learning-based object detection model that can quickly recognize and classify objects in real-time.
To explore potential future directions for the technology, such as optimizing its performance on new datasets, incorporating additional features or modalities, or integrating it into existing assistive technology devices.

# Future scope
GPS Embedded Navigation
Connectivity 
Integration with wearable devices
More customization


# Model training
![1](https://user-images.githubusercontent.com/114243701/230757200-74014209-9ba8-4eaa-a2d2-8c48cab61b53.jpg)

# Tasks done by the model
![3](https://user-images.githubusercontent.com/114243701/230757220-08064f8d-d379-407d-bce0-1489f09402a5.jpg)

# Output of the model
![4](https://user-images.githubusercontent.com/114243701/230757248-2d148428-e714-498b-83da-704cac47e584.jpg)
